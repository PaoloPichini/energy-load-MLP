{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is a project using the https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/data data and training a simple MultiLayer Perceptron to predict future energy loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model hyperparameters from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration:\n",
      "{'data_params': {'num_samples': 1000, 'max_int': 128}, 'model_params': {'model': 'MLP', 'input_dim': 24, 'hidden_dim': 512, 'output_dim': 1}, 'training_params': {'learning_rate': 0.001, 'batch_size': 128, 'window_length': 24, 'num_epochs': 100, 'optimizer': 'Adam'}, 'log_params': {'experiment_name': 'experiment_001', 'notes': 'Baseline experiment with MLP'}}\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from a JSON file\n",
    "import json\n",
    "with open(\"config1.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Access parameters like:\n",
    "num_samples = config[\"data_params\"][\"num_samples\"]\n",
    "max_int = config[\"data_params\"][\"max_int\"]\n",
    "\n",
    "#input_dim = config[\"model_params\"][\"input_dim\"]\n",
    "hidden_dim = config[\"model_params\"][\"hidden_dim\"]\n",
    "output_dim = config[\"model_params\"][\"output_dim\"]\n",
    "\n",
    "learning_rate = config[\"training_params\"][\"learning_rate\"]\n",
    "batch_size = config[\"training_params\"][\"batch_size\"]\n",
    "window_length = config[\"training_params\"][\"window_length\"]\n",
    "num_epochs = config[\"training_params\"][\"num_epochs\"]\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:29.855415Z",
     "iopub.status.busy": "2026-01-18T15:32:29.855033Z",
     "iopub.status.idle": "2026-01-18T15:32:30.833634Z",
     "shell.execute_reply": "2026-01-18T15:32:30.832663Z",
     "shell.execute_reply.started": "2026-01-18T15:32:29.855331Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to dataset via Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/Desktop/Projects/Solo/energy-load-MLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/paolo/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"robikscube/hourly-energy-consumption\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:33.777891Z",
     "iopub.status.busy": "2026-01-18T15:32:33.777517Z",
     "iopub.status.idle": "2026-01-18T15:32:33.796431Z",
     "shell.execute_reply": "2026-01-18T15:32:33.795415Z",
     "shell.execute_reply.started": "2026-01-18T15:32:33.777822Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['est_hourly.paruqet', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv', 'DAYTON_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'FE_hourly.csv', 'DOM_hourly.csv', 'EKPC_hourly.csv', 'DEOK_hourly.csv', 'DUQ_hourly.csv', 'AEP_hourly.csv', 'COMED_hourly.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(FROM KAGGLE, adapted) functions for plotting data\n",
    "\n",
    "This function selects one of the column (e.g. load values in MW) and plots its value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:43.565637Z",
     "iopub.status.busy": "2026-01-18T15:32:43.565225Z",
     "iopub.status.idle": "2026-01-18T15:32:43.574390Z",
     "shell.execute_reply": "2026-01-18T15:32:43.573017Z",
     "shell.execute_reply.started": "2026-01-18T15:32:43.565563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotDistribution(df, plotCol, nBins):\n",
    "    # plotCol is 1-based index, convert to 0-based\n",
    "    col_idx = plotCol - 1\n",
    "    columnNames = list(df)\n",
    "    # Check if col_idx is within the valid range\n",
    "    if col_idx < 0 or col_idx >= len(columnNames):\n",
    "        raise IndexError(f\"plotCol {plotCol} is out of range\")\n",
    "    # Get the specific column data\n",
    "    columnDf = df.iloc[:, col_idx]\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(6, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    # Determine if the column is categorical or numerical\n",
    "    if not np.issubdtype(columnDf.dtype, np.number):\n",
    "        columnDf.value_counts().plot.bar()\n",
    "    else:\n",
    "        columnDf.hist(bins=nBins)\n",
    "    # Labeling the plot\n",
    "    plt.ylabel('counts')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{columnNames[col_idx]} (column {plotCol})')\n",
    "    plt.tight_layout(pad=1.0, w_pad=1.0, h_pad=1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 1: AEP_hourly.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select number of rows to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:01.577518Z",
     "iopub.status.busy": "2026-01-18T15:33:01.577142Z",
     "iopub.status.idle": "2026-01-18T15:33:01.613502Z",
     "shell.execute_reply": "2026-01-18T15:33:01.612147Z",
     "shell.execute_reply.started": "2026-01-18T15:33:01.577462Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 121273 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "# AEP_hourly.csv has 121273 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df1 = pd.read_csv(os.path.join(path, \"AEP_hourly.csv\"), delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'AEP_hourly.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:04.414257Z",
     "iopub.status.busy": "2026-01-18T15:33:04.413919Z",
     "iopub.status.idle": "2026-01-18T15:33:04.442050Z",
     "shell.execute_reply": "2026-01-18T15:33:04.440839Z",
     "shell.execute_reply.started": "2026-01-18T15:33:04.414204Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AEP_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-12-31 01:00:00</td>\n",
       "      <td>13478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-12-31 02:00:00</td>\n",
       "      <td>12865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-12-31 03:00:00</td>\n",
       "      <td>12577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-12-31 04:00:00</td>\n",
       "      <td>12517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-12-31 05:00:00</td>\n",
       "      <td>12670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   AEP_MW\n",
       "0  2004-12-31 01:00:00  13478.0\n",
       "1  2004-12-31 02:00:00  12865.0\n",
       "2  2004-12-31 03:00:00  12577.0\n",
       "3  2004-12-31 04:00:00  12517.0\n",
       "4  2004-12-31 05:00:00  12670.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:35.590232Z",
     "iopub.status.busy": "2026-01-18T15:33:35.589928Z",
     "iopub.status.idle": "2026-01-18T15:33:35.608131Z",
     "shell.execute_reply": "2026-01-18T15:33:35.606958Z",
     "shell.execute_reply.started": "2026-01-18T15:33:35.590181Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotDistribution(df1, 2, 1000) # Select '2' to plot the 2nd column (energy load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 2: COMED_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:43.868540Z",
     "iopub.status.busy": "2026-01-18T15:33:43.868172Z",
     "iopub.status.idle": "2026-01-18T15:33:43.893631Z",
     "shell.execute_reply": "2026-01-18T15:33:43.892267Z",
     "shell.execute_reply.started": "2026-01-18T15:33:43.868475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# COMED_hourly.csv has 66497 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df2 = pd.read_csv(os.path.join(path,'COMED_hourly.csv'), delimiter=',', nrows = nRowsRead)\n",
    "df2.dataframeName = 'COMED_hourly.csv'\n",
    "nRow, nCol = df2.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:46.157174Z",
     "iopub.status.busy": "2026-01-18T15:33:46.156854Z",
     "iopub.status.idle": "2026-01-18T15:33:46.171765Z",
     "shell.execute_reply": "2026-01-18T15:33:46.170478Z",
     "shell.execute_reply.started": "2026-01-18T15:33:46.157123Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>COMED_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>9970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>9428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>9059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>8817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>8743.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  COMED_MW\n",
       "0  2011-12-31 01:00:00    9970.0\n",
       "1  2011-12-31 02:00:00    9428.0\n",
       "2  2011-12-31 03:00:00    9059.0\n",
       "3  2011-12-31 04:00:00    8817.0\n",
       "4  2011-12-31 05:00:00    8743.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:48.811182Z",
     "iopub.status.busy": "2026-01-18T15:33:48.810850Z",
     "iopub.status.idle": "2026-01-18T15:33:48.829250Z",
     "shell.execute_reply": "2026-01-18T15:33:48.828214Z",
     "shell.execute_reply.started": "2026-01-18T15:33:48.811130Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerColumnDistribution(df2, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 3: DAYTON_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:52.655642Z",
     "iopub.status.busy": "2026-01-18T15:33:52.655299Z",
     "iopub.status.idle": "2026-01-18T15:33:52.683691Z",
     "shell.execute_reply": "2026-01-18T15:33:52.682397Z",
     "shell.execute_reply.started": "2026-01-18T15:33:52.655588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# DAYTON_hourly.csv has 121275 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df3 = pd.read_csv(os.path.join(path,'DAYTON_hourly.csv'), delimiter=',', nrows = nRowsRead)\n",
    "df3.dataframeName = 'DAYTON_hourly.csv'\n",
    "nRow, nCol = df3.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:58.807725Z",
     "iopub.status.busy": "2026-01-18T15:33:58.807434Z",
     "iopub.status.idle": "2026-01-18T15:33:58.822935Z",
     "shell.execute_reply": "2026-01-18T15:33:58.821372Z",
     "shell.execute_reply.started": "2026-01-18T15:33:58.807682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>DAYTON_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-12-31 01:00:00</td>\n",
       "      <td>1596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-12-31 02:00:00</td>\n",
       "      <td>1517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-12-31 03:00:00</td>\n",
       "      <td>1486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-12-31 04:00:00</td>\n",
       "      <td>1469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-12-31 05:00:00</td>\n",
       "      <td>1472.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  DAYTON_MW\n",
       "0  2004-12-31 01:00:00     1596.0\n",
       "1  2004-12-31 02:00:00     1517.0\n",
       "2  2004-12-31 03:00:00     1486.0\n",
       "3  2004-12-31 04:00:00     1469.0\n",
       "4  2004-12-31 05:00:00     1472.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:34:01.916482Z",
     "iopub.status.busy": "2026-01-18T15:34:01.916121Z",
     "iopub.status.idle": "2026-01-18T15:34:01.933226Z",
     "shell.execute_reply": "2026-01-18T15:34:01.932433Z",
     "shell.execute_reply.started": "2026-01-18T15:34:01.916421Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerColumnDistribution(df3, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "In this section we define the MLP which we will train on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start by importing the necessary libraries\n",
    "import torch  # Main framework for defining and training the transformer\n",
    "import torch.nn as nn  # Neural network module\n",
    "import torch.optim as optim  # Optimization functions\n",
    "import itertools  # (Optional) For generating structured datasets\n",
    "import math  # For mathematical operations\n",
    "\n",
    "import time # For timing the training process\n",
    "\n",
    "import json # For saving and loading the model\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence # For padding sequences to the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also define a simple MLP model for comparison\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=window_length, hidden_dim=128, output_dim=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)  # No activation on output (for regression)\n",
    "        return x\n",
    "\n",
    "# define model\n",
    "#model = ModuloTransformer(num_primes=len(primes), d_model=256, num_heads=4, num_layers=2, hidden_dim=256)\n",
    "model = MLP(input_dim=window_length, hidden_dim=hidden_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries to package data into batches and in the appropriate format to feed into the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader  # To handle training data efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset AEP_hourly.csv containing the American Electric Power hourly energy consumption\n",
    "\n",
    "Note: we use this dataset as example, but the process can be repeated with the other sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121249, 24) (121249, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load AEP data\n",
    "# Import csv as pandas DataFrame\n",
    "df = pd.read_csv(f\"{path}/AEP_hourly.csv\")\n",
    "# convert \"Datetime\" strings to datetime type\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n",
    "# NOTE data is not ordered properly, see eg\n",
    "# print((df[\"Datetime\"][20:24+1]))\n",
    "# hence order\n",
    "df = df.sort_values(\"Datetime\")\n",
    "\n",
    "# take all MW energy load entries as a numpy array of float32\n",
    "# NB float32 works better with PyTorch\n",
    "series = df[\"AEP_MW\"].values.astype(np.float32)\n",
    "\n",
    "# Sliding window\n",
    "# create input vectors X containing L consecutive values for the energy loads\n",
    "# create target values y containing the next value after each input vector\n",
    "L = window_length  # window length; change as desired\n",
    "X = np.array([series[i:i+L] for i in range(len(series) - L)], dtype=np.float32)\n",
    "y = np.array([series[i+L] for i in range(len(series) - L)], dtype=np.float32)\n",
    "# convert y to (num_samples, 1) shape ie into a 2D array, needed to agree with MLP shape\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# check\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into:\n",
    "\n",
    "(1) training set, used to train the model\n",
    "\n",
    "(2) validation set, used during the training to test the model (e.g. to avoid overfitting)\n",
    "\n",
    "(3) testing set, used to test the model after the training\n",
    "\n",
    "Then package into the appropriate PyTorch formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: (n, L), y: (n, 1)\n",
    "n = len(X)\n",
    "# define (integer) boundaries for train/val/test splits\n",
    "train_end = int(n * 0.7)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "# implement splits\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "# normalise data (z-score normalisation)\n",
    "# NB standardize using train stats only\n",
    "mean = X_train.mean(axis=0, keepdims=True)\n",
    "std = X_train.std(axis=0, keepdims=True) + 1e-8\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Torch datasets/loaders\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_ds = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "test_ds = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first batch of data as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inputs (time series): torch.Size([128, 24])\n",
      "Batch Inputs (time series): tensor([[ 0.4007,  0.2990,  0.1361,  ...,  0.3037,  0.3845,  0.2867],\n",
      "        [ 0.1621,  0.4224,  0.3537,  ..., -0.9796, -0.8500, -0.4737],\n",
      "        [-0.9395, -1.0396, -0.9507,  ..., -0.8493, -0.9536, -1.0972],\n",
      "        ...,\n",
      "        [-0.1879, -0.5084, -0.7509,  ...,  0.4485,  0.1800, -0.2856],\n",
      "        [ 1.5561,  1.8847,  2.0974,  ..., -0.7794, -0.2588,  0.1303],\n",
      "        [-0.2069,  0.1500,  0.4162,  ..., -0.2794, -0.2324, -0.1238]])\n",
      "Batch Targets (next step): torch.Size([128, 1])\n",
      "Batch Targets (next step): tensor([[16110.],\n",
      "        [16182.],\n",
      "        [12644.],\n",
      "        [23426.],\n",
      "        [15708.],\n",
      "        [20359.],\n",
      "        [16361.],\n",
      "        [20801.],\n",
      "        [16874.],\n",
      "        [14485.],\n",
      "        [13143.],\n",
      "        [19589.],\n",
      "        [17793.],\n",
      "        [14522.],\n",
      "        [15856.],\n",
      "        [11320.],\n",
      "        [17890.],\n",
      "        [19420.],\n",
      "        [11171.],\n",
      "        [16718.],\n",
      "        [18531.],\n",
      "        [17019.],\n",
      "        [19412.],\n",
      "        [17167.],\n",
      "        [13559.],\n",
      "        [15856.],\n",
      "        [16818.],\n",
      "        [14465.],\n",
      "        [18528.],\n",
      "        [17332.],\n",
      "        [14250.],\n",
      "        [15849.],\n",
      "        [16135.],\n",
      "        [15728.],\n",
      "        [16646.],\n",
      "        [19660.],\n",
      "        [16957.],\n",
      "        [19460.],\n",
      "        [12583.],\n",
      "        [14539.],\n",
      "        [15186.],\n",
      "        [19681.],\n",
      "        [14634.],\n",
      "        [14966.],\n",
      "        [12366.],\n",
      "        [17609.],\n",
      "        [13653.],\n",
      "        [11723.],\n",
      "        [15241.],\n",
      "        [14476.],\n",
      "        [17252.],\n",
      "        [11483.],\n",
      "        [14012.],\n",
      "        [19383.],\n",
      "        [18151.],\n",
      "        [18888.],\n",
      "        [19841.],\n",
      "        [15533.],\n",
      "        [13061.],\n",
      "        [15715.],\n",
      "        [13987.],\n",
      "        [13089.],\n",
      "        [12243.],\n",
      "        [16964.],\n",
      "        [14576.],\n",
      "        [19990.],\n",
      "        [17904.],\n",
      "        [15308.],\n",
      "        [19223.],\n",
      "        [15704.],\n",
      "        [19381.],\n",
      "        [17351.],\n",
      "        [15710.],\n",
      "        [15336.],\n",
      "        [12961.],\n",
      "        [12764.],\n",
      "        [14990.],\n",
      "        [19228.],\n",
      "        [15102.],\n",
      "        [12606.],\n",
      "        [13301.],\n",
      "        [16728.],\n",
      "        [14195.],\n",
      "        [15358.],\n",
      "        [16372.],\n",
      "        [13534.],\n",
      "        [15987.],\n",
      "        [18898.],\n",
      "        [17439.],\n",
      "        [13912.],\n",
      "        [17316.],\n",
      "        [16319.],\n",
      "        [16570.],\n",
      "        [10957.],\n",
      "        [16520.],\n",
      "        [16994.],\n",
      "        [14014.],\n",
      "        [13854.],\n",
      "        [16748.],\n",
      "        [17652.],\n",
      "        [21455.],\n",
      "        [11350.],\n",
      "        [14729.],\n",
      "        [16465.],\n",
      "        [12689.],\n",
      "        [16182.],\n",
      "        [19334.],\n",
      "        [16135.],\n",
      "        [11925.],\n",
      "        [14080.],\n",
      "        [18402.],\n",
      "        [13805.],\n",
      "        [13477.],\n",
      "        [13285.],\n",
      "        [13671.],\n",
      "        [15938.],\n",
      "        [19657.],\n",
      "        [17162.],\n",
      "        [10459.],\n",
      "        [17456.],\n",
      "        [18115.],\n",
      "        [14852.],\n",
      "        [18034.],\n",
      "        [16602.],\n",
      "        [15773.],\n",
      "        [13902.],\n",
      "        [17064.],\n",
      "        [15929.]])\n"
     ]
    }
   ],
   "source": [
    "# Check one batch of data\n",
    "for batch in train_loader:\n",
    "    inputs, targets = batch  # Unpack batch\n",
    "    print(f\"Batch Inputs (time series): {inputs.shape}\")  # Should be (batch_size, window_length)\n",
    "    print(f\"Batch Inputs (time series): {inputs}\")\n",
    "    print(f\"Batch Targets (next step): {targets.shape}\")  # Should be (batch_size,1)\n",
    "    print(f\"Batch Targets (next step): {targets}\")\n",
    "    break  # Only print the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training loop and train the model.\n",
    "\n",
    "Note:\n",
    "\n",
    "(1) we use Mean Squared Loss as a loss function, since the output is a float representing the energy power in MW\n",
    "\n",
    "(2) we leave the option to turn on a scheduler to update the learining rate during training\n",
    "\n",
    "(3) we keep track of both training and validation loss, e.g. to make sure the model is training but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | train 67859747.0075 | val 10579786.7032\n",
      "Epoch 2/100 | train 2882355.4729 | val 337572.9402\n",
      "Epoch 3/100 | train 226316.8645 | val 142360.4173\n",
      "Epoch 4/100 | train 132316.3191 | val 94995.9657\n",
      "Epoch 5/100 | train 94505.5671 | val 70959.0202\n",
      "Epoch 6/100 | train 74670.8230 | val 54534.1648\n",
      "Epoch 7/100 | train 64722.7336 | val 48113.2614\n",
      "Epoch 8/100 | train 60028.2724 | val 47414.6304\n",
      "Epoch 9/100 | train 57793.1256 | val 53154.8832\n",
      "Epoch 10/100 | train 56295.2997 | val 47766.2634\n",
      "Epoch 11/100 | train 56013.7025 | val 44344.4758\n",
      "Epoch 12/100 | train 55298.4734 | val 46224.6003\n",
      "Epoch 13/100 | train 54561.4276 | val 69002.8967\n",
      "Epoch 14/100 | train 55116.1175 | val 44379.1321\n",
      "Epoch 15/100 | train 54295.0166 | val 41716.6603\n",
      "Epoch 16/100 | train 53930.0591 | val 47145.4674\n",
      "Epoch 17/100 | train 53824.5643 | val 46056.1636\n",
      "Epoch 18/100 | train 53415.2024 | val 48961.8391\n",
      "Epoch 19/100 | train 53065.7844 | val 40930.8296\n",
      "Epoch 20/100 | train 52698.1573 | val 41454.8349\n",
      "Epoch 21/100 | train 52448.0696 | val 41339.4211\n",
      "Epoch 22/100 | train 52242.4468 | val 43912.6797\n",
      "Epoch 23/100 | train 52185.0507 | val 40512.4128\n",
      "Epoch 24/100 | train 52086.7641 | val 42801.8588\n",
      "Epoch 25/100 | train 51804.7797 | val 40267.0643\n",
      "Epoch 26/100 | train 51847.7712 | val 40033.5820\n",
      "Epoch 27/100 | train 50970.5140 | val 40518.5384\n",
      "Epoch 28/100 | train 51559.0974 | val 39554.5351\n",
      "Epoch 29/100 | train 51136.6679 | val 40610.9408\n",
      "Epoch 30/100 | train 50718.9105 | val 42104.9436\n",
      "Epoch 31/100 | train 50447.6903 | val 41763.5990\n",
      "Epoch 32/100 | train 50963.7259 | val 43965.3248\n",
      "Epoch 33/100 | train 50644.4821 | val 40687.8080\n",
      "Epoch 34/100 | train 50287.0432 | val 41338.0830\n",
      "Epoch 35/100 | train 49923.7182 | val 39941.5775\n",
      "Epoch 36/100 | train 49838.2163 | val 39330.4754\n",
      "Epoch 37/100 | train 49713.8294 | val 42614.4928\n",
      "Epoch 38/100 | train 49963.1485 | val 41239.5231\n",
      "Epoch 39/100 | train 49462.8429 | val 51072.5996\n",
      "Epoch 40/100 | train 49422.8634 | val 46942.9450\n",
      "Epoch 41/100 | train 49303.9299 | val 41774.4703\n",
      "Epoch 42/100 | train 48797.8079 | val 39055.4570\n",
      "Epoch 43/100 | train 47698.8991 | val 38783.0272\n",
      "Epoch 44/100 | train 47178.8400 | val 38943.9251\n",
      "Epoch 45/100 | train 47038.9041 | val 44162.5871\n",
      "Epoch 46/100 | train 46817.6261 | val 36565.6668\n",
      "Epoch 47/100 | train 46440.5988 | val 44501.9380\n",
      "Epoch 48/100 | train 45627.6741 | val 49774.7673\n",
      "Epoch 49/100 | train 45164.3930 | val 40441.3489\n",
      "Epoch 50/100 | train 45917.8959 | val 37709.8817\n",
      "Epoch 51/100 | train 45068.6829 | val 45113.9652\n",
      "Epoch 52/100 | train 44792.3267 | val 40873.8879\n",
      "Epoch 53/100 | train 45328.9777 | val 37738.2116\n",
      "Epoch 54/100 | train 44752.7900 | val 45916.7964\n",
      "Epoch 55/100 | train 44322.7831 | val 39522.4399\n",
      "Epoch 56/100 | train 44223.1574 | val 35313.0070\n",
      "Epoch 57/100 | train 44027.0003 | val 35328.1171\n",
      "Epoch 58/100 | train 43538.2533 | val 36445.4299\n",
      "Epoch 59/100 | train 43897.1932 | val 35244.0571\n",
      "Epoch 60/100 | train 44090.6136 | val 40116.5874\n",
      "Epoch 61/100 | train 43720.7588 | val 35013.7163\n",
      "Epoch 62/100 | train 43118.9276 | val 37333.3768\n",
      "Epoch 63/100 | train 43271.6624 | val 35948.3249\n",
      "Epoch 64/100 | train 42400.0486 | val 33556.4375\n",
      "Epoch 65/100 | train 42029.8146 | val 34050.8691\n",
      "Epoch 66/100 | train 42380.1022 | val 44958.5293\n",
      "Epoch 67/100 | train 42015.9436 | val 64910.4893\n",
      "Epoch 68/100 | train 42012.8815 | val 33537.8582\n",
      "Epoch 69/100 | train 41810.6319 | val 40999.2165\n",
      "Epoch 70/100 | train 41361.4870 | val 32669.8779\n",
      "Epoch 71/100 | train 41515.9844 | val 43602.4106\n",
      "Epoch 72/100 | train 41663.7304 | val 34047.5222\n",
      "Epoch 73/100 | train 41403.6735 | val 33939.5589\n",
      "Epoch 74/100 | train 41531.4507 | val 38265.0019\n",
      "Epoch 75/100 | train 41034.0770 | val 37962.8504\n",
      "Epoch 76/100 | train 40707.4744 | val 34412.0696\n",
      "Epoch 77/100 | train 40928.9260 | val 33652.5983\n",
      "Epoch 78/100 | train 40514.1850 | val 38209.0095\n",
      "Epoch 79/100 | train 40327.5770 | val 35265.3859\n",
      "Epoch 80/100 | train 39553.3649 | val 34904.4952\n",
      "Epoch 81/100 | train 39524.5700 | val 33796.8843\n",
      "Epoch 82/100 | train 39387.0755 | val 41563.6359\n",
      "Epoch 83/100 | train 39285.0552 | val 36556.9622\n",
      "Epoch 84/100 | train 39339.4880 | val 64228.7136\n",
      "Epoch 85/100 | train 38885.8851 | val 32830.8965\n",
      "Epoch 86/100 | train 38866.3427 | val 33787.9706\n",
      "Epoch 87/100 | train 38252.8380 | val 32877.9337\n",
      "Epoch 88/100 | train 38523.8431 | val 32784.9278\n",
      "Epoch 89/100 | train 38076.3800 | val 32142.3848\n",
      "Epoch 90/100 | train 37542.3702 | val 45626.3868\n",
      "Epoch 91/100 | train 38245.9387 | val 32876.6711\n",
      "Epoch 92/100 | train 37877.4646 | val 31424.6275\n",
      "Epoch 93/100 | train 36909.7898 | val 31913.6393\n",
      "Epoch 94/100 | train 37347.1547 | val 36322.0847\n",
      "Epoch 95/100 | train 37488.4992 | val 30869.6168\n",
      "Epoch 96/100 | train 36868.2531 | val 29912.0615\n",
      "Epoch 97/100 | train 36656.9056 | val 52622.6669\n",
      "Epoch 98/100 | train 36432.2975 | val 33349.2862\n",
      "Epoch 99/100 | train 36174.2770 | val 33728.9827\n",
      "Epoch 100/100 | train 36099.5253 | val 30950.4616\n",
      "Training completed in 73.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now we define the training loop\n",
    "# We define the loss function (Mean Squared Error) and the optimizer (Adam)\n",
    "# Then we iterate over the data in batches, perform forward pass, compute loss, backpropagate and update weights\n",
    "\n",
    "# Define Mean Squared Error loss (for regression)\n",
    "#loss_fn = nn.MSELoss()\n",
    "# Define Cross Entropy loss (for classification)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)  # Reduce LR by gamma after step_size epochs\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)  # Cosine annealing scheduler, gradually reduces learning rate, specify eta_min=X for minimum LR value (default 0)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)  # Reduce LR on plateau, reduce LR by factor of 0.5 if validation loss does not improve for 10 epochs\n",
    "\n",
    "# Check output for a single training step\n",
    "#optimizer.zero_grad()  # Reset gradients\n",
    "#test_outputs = model(test_inputs)  # Forward pass (predict N)\n",
    "#test_loss = loss_fn(test_outputs, test_targets)  # Compute loss\n",
    "#test_loss.backward()  # Backpropagation\n",
    "#optimizer.step()  # Update weights\n",
    "#print(\"Model Output After One Training Step:\")\n",
    "#print(model(test_inputs))\n",
    "\n",
    "\n",
    "start_time = time.time()  # Track how long training takes\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0  # Track total loss for the epoch\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for inputs, targets in train_loader:  # Iterate over batches\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(inputs)  # Forward pass (predict N)\n",
    "        loss = loss_fn(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        train_loss += loss.item()  # Keep track of loss\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler every epoch\n",
    "    #scheduler.step()\n",
    "    # Use for the ReduceLROnPlateau scheduler\n",
    "    #scheduler.step(total_loss)\n",
    "\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")  # Print total time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the trained model\n",
    "\n",
    "We begin by computing mean squared error (MSE), root mean squared error (RMSE) and mean absolute error (MAE) with respect to the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 29234.6641 | RMSE: 170.9815 | MAE: 127.4107\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "preds = []\n",
    "targets_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        preds.append(outputs.cpu())\n",
    "        targets_all.append(targets.cpu())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "targets_all = torch.cat(targets_all).numpy()\n",
    "\n",
    "# Metrics\n",
    "mse = ((preds - targets_all) ** 2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.abs(preds - targets_all).mean()\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compare MSE/RMSE/MAE against a simple baseline, obtained by using the MW value for the last hour (in each sequence in X_test) as prediction for the next hour. If the model has trained well we expect it to give better results than this baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 286020.5312 | RMSE: 534.8089 | MAE: 417.4123\n"
     ]
    }
   ],
   "source": [
    "# De-normalize last input value to MW\n",
    "last_norm = X_test[:, -1]  # z-score-normalized last value\n",
    "last_raw = last_norm * std[0, -1] + mean[0, -1] # de-normalize\n",
    "\n",
    "baseline_pred = last_raw\n",
    "baseline_true = y_test.squeeze()\n",
    "\n",
    "baseline_mse = ((baseline_pred - baseline_true) ** 2).mean()\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "baseline_mae = np.abs(baseline_pred - baseline_true).mean()\n",
    "\n",
    "print(f\"Baseline MSE: {baseline_mse:.4f} | RMSE: {baseline_rmse:.4f} | MAE: {baseline_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we create a table displaying predicted VS actual power for a few datapoints in the training set, including absolute and relative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>rel_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12168.0</td>\n",
       "      <td>12360.610352</td>\n",
       "      <td>192.610352</td>\n",
       "      <td>0.015829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12568.0</td>\n",
       "      <td>12639.185547</td>\n",
       "      <td>71.185547</td>\n",
       "      <td>0.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13203.0</td>\n",
       "      <td>13355.710938</td>\n",
       "      <td>152.710938</td>\n",
       "      <td>0.011566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14019.0</td>\n",
       "      <td>13983.339844</td>\n",
       "      <td>35.660156</td>\n",
       "      <td>0.002544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14901.0</td>\n",
       "      <td>14813.066406</td>\n",
       "      <td>87.933594</td>\n",
       "      <td>0.005901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15815.0</td>\n",
       "      <td>15697.333984</td>\n",
       "      <td>117.666016</td>\n",
       "      <td>0.007440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16821.0</td>\n",
       "      <td>16734.433594</td>\n",
       "      <td>86.566406</td>\n",
       "      <td>0.005146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17623.0</td>\n",
       "      <td>17700.937500</td>\n",
       "      <td>77.937500</td>\n",
       "      <td>0.004422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18382.0</td>\n",
       "      <td>18348.382812</td>\n",
       "      <td>33.617188</td>\n",
       "      <td>0.001829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18931.0</td>\n",
       "      <td>18980.830078</td>\n",
       "      <td>49.830078</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19409.0</td>\n",
       "      <td>19238.070312</td>\n",
       "      <td>170.929688</td>\n",
       "      <td>0.008807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19312.0</td>\n",
       "      <td>19624.052734</td>\n",
       "      <td>312.052734</td>\n",
       "      <td>0.016158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19231.0</td>\n",
       "      <td>19236.167969</td>\n",
       "      <td>5.167969</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19295.0</td>\n",
       "      <td>19016.251953</td>\n",
       "      <td>278.748047</td>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19451.0</td>\n",
       "      <td>19073.373047</td>\n",
       "      <td>377.626953</td>\n",
       "      <td>0.019414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18967.0</td>\n",
       "      <td>19053.574219</td>\n",
       "      <td>86.574219</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18434.0</td>\n",
       "      <td>18502.269531</td>\n",
       "      <td>68.269531</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18097.0</td>\n",
       "      <td>18195.667969</td>\n",
       "      <td>98.667969</td>\n",
       "      <td>0.005452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16983.0</td>\n",
       "      <td>17366.671875</td>\n",
       "      <td>383.671875</td>\n",
       "      <td>0.022592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15641.0</td>\n",
       "      <td>15598.558594</td>\n",
       "      <td>42.441406</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target          pred   abs_error  rel_error\n",
       "0   12168.0  12360.610352  192.610352   0.015829\n",
       "1   12568.0  12639.185547   71.185547   0.005664\n",
       "2   13203.0  13355.710938  152.710938   0.011566\n",
       "3   14019.0  13983.339844   35.660156   0.002544\n",
       "4   14901.0  14813.066406   87.933594   0.005901\n",
       "5   15815.0  15697.333984  117.666016   0.007440\n",
       "6   16821.0  16734.433594   86.566406   0.005146\n",
       "7   17623.0  17700.937500   77.937500   0.004422\n",
       "8   18382.0  18348.382812   33.617188   0.001829\n",
       "9   18931.0  18980.830078   49.830078   0.002632\n",
       "10  19409.0  19238.070312  170.929688   0.008807\n",
       "11  19312.0  19624.052734  312.052734   0.016158\n",
       "12  19231.0  19236.167969    5.167969   0.000269\n",
       "13  19295.0  19016.251953  278.748047   0.014447\n",
       "14  19451.0  19073.373047  377.626953   0.019414\n",
       "15  18967.0  19053.574219   86.574219   0.004564\n",
       "16  18434.0  18502.269531   68.269531   0.003703\n",
       "17  18097.0  18195.667969   98.667969   0.005452\n",
       "18  16983.0  17366.671875  383.671875   0.022592\n",
       "19  15641.0  15598.558594   42.441406   0.002713"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "targets_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        preds.append(outputs.cpu().numpy())\n",
    "        targets_all.append(targets.cpu().numpy())\n",
    "\n",
    "preds = np.vstack(preds).squeeze()\n",
    "targets_all = np.vstack(targets_all).squeeze()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"target\": targets_all,\n",
    "    \"pred\": preds\n",
    "})\n",
    "#results[\"error\"] = results[\"pred\"] - results[\"target\"]\n",
    "results[\"abs_error\"] = (results[\"pred\"] - results[\"target\"]).abs()\n",
    "results[\"rel_error\"] = results[\"abs_error\"]/results[\"target\"]\n",
    "\n",
    "results.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 48149,
     "sourceId": 87794,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 25114,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
