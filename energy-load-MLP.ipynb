{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is a project using the https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/data data and training a simple MultiLayer Perceptron to predict future energy loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model hyperparameters from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration:\n",
      "{'data_params': {'num_samples': 1000, 'max_int': 128}, 'model_params': {'model': 'MLP', 'input_dim': 24, 'hidden_dim': 512, 'output_dim': 1}, 'training_params': {'learning_rate': 0.001, 'batch_size': 128, 'window_length': 24, 'num_epochs': 100, 'optimizer': 'Adam'}, 'log_params': {'experiment_name': 'experiment_001', 'notes': 'Baseline experiment with MLP'}}\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from a JSON file\n",
    "import json\n",
    "with open(\"config1.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Access parameters like:\n",
    "num_samples = config[\"data_params\"][\"num_samples\"]\n",
    "max_int = config[\"data_params\"][\"max_int\"]\n",
    "\n",
    "#input_dim = config[\"model_params\"][\"input_dim\"]\n",
    "hidden_dim = config[\"model_params\"][\"hidden_dim\"]\n",
    "output_dim = config[\"model_params\"][\"output_dim\"]\n",
    "\n",
    "learning_rate = config[\"training_params\"][\"learning_rate\"]\n",
    "batch_size = config[\"training_params\"][\"batch_size\"]\n",
    "window_length = config[\"training_params\"][\"window_length\"]\n",
    "num_epochs = config[\"training_params\"][\"num_epochs\"]\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:29.855415Z",
     "iopub.status.busy": "2026-01-18T15:32:29.855033Z",
     "iopub.status.idle": "2026-01-18T15:32:30.833634Z",
     "shell.execute_reply": "2026-01-18T15:32:30.832663Z",
     "shell.execute_reply.started": "2026-01-18T15:32:29.855331Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to dataset via Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/Desktop/Projects/Solo/energy-load-MLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/paolo/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"robikscube/hourly-energy-consumption\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:33.777891Z",
     "iopub.status.busy": "2026-01-18T15:32:33.777517Z",
     "iopub.status.idle": "2026-01-18T15:32:33.796431Z",
     "shell.execute_reply": "2026-01-18T15:32:33.795415Z",
     "shell.execute_reply.started": "2026-01-18T15:32:33.777822Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['est_hourly.paruqet', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv', 'DAYTON_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'FE_hourly.csv', 'DOM_hourly.csv', 'EKPC_hourly.csv', 'DEOK_hourly.csv', 'DUQ_hourly.csv', 'AEP_hourly.csv', 'COMED_hourly.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(FROM KAGGLE) functions for plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:43.565637Z",
     "iopub.status.busy": "2026-01-18T15:32:43.565225Z",
     "iopub.status.idle": "2026-01-18T15:32:43.574390Z",
     "shell.execute_reply": "2026-01-18T15:32:43.573017Z",
     "shell.execute_reply.started": "2026-01-18T15:32:43.565563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:46.292840Z",
     "iopub.status.busy": "2026-01-18T15:32:46.292518Z",
     "iopub.status.idle": "2026-01-18T15:32:46.301748Z",
     "shell.execute_reply": "2026-01-18T15:32:46.300213Z",
     "shell.execute_reply.started": "2026-01-18T15:32:46.292773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:32:49.110623Z",
     "iopub.status.busy": "2026-01-18T15:32:49.110316Z",
     "iopub.status.idle": "2026-01-18T15:32:49.119020Z",
     "shell.execute_reply": "2026-01-18T15:32:49.117069Z",
     "shell.execute_reply.started": "2026-01-18T15:32:49.110571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scatter and density plots\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 1: AEP_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:01.577518Z",
     "iopub.status.busy": "2026-01-18T15:33:01.577142Z",
     "iopub.status.idle": "2026-01-18T15:33:01.613502Z",
     "shell.execute_reply": "2026-01-18T15:33:01.612147Z",
     "shell.execute_reply.started": "2026-01-18T15:33:01.577462Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# AEP_hourly.csv has 121273 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df1 = pd.read_csv(os.path.join(path, \"AEP_hourly.csv\"), delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'AEP_hourly.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:04.414257Z",
     "iopub.status.busy": "2026-01-18T15:33:04.413919Z",
     "iopub.status.idle": "2026-01-18T15:33:04.442050Z",
     "shell.execute_reply": "2026-01-18T15:33:04.440839Z",
     "shell.execute_reply.started": "2026-01-18T15:33:04.414204Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AEP_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-12-31 01:00:00</td>\n",
       "      <td>13478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-12-31 02:00:00</td>\n",
       "      <td>12865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-12-31 03:00:00</td>\n",
       "      <td>12577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-12-31 04:00:00</td>\n",
       "      <td>12517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-12-31 05:00:00</td>\n",
       "      <td>12670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   AEP_MW\n",
       "0  2004-12-31 01:00:00  13478.0\n",
       "1  2004-12-31 02:00:00  12865.0\n",
       "2  2004-12-31 03:00:00  12577.0\n",
       "3  2004-12-31 04:00:00  12517.0\n",
       "4  2004-12-31 05:00:00  12670.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:35.590232Z",
     "iopub.status.busy": "2026-01-18T15:33:35.589928Z",
     "iopub.status.idle": "2026-01-18T15:33:35.608131Z",
     "shell.execute_reply": "2026-01-18T15:33:35.606958Z",
     "shell.execute_reply.started": "2026-01-18T15:33:35.590181Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerColumnDistribution(df1, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 2: COMED_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:43.868540Z",
     "iopub.status.busy": "2026-01-18T15:33:43.868172Z",
     "iopub.status.idle": "2026-01-18T15:33:43.893631Z",
     "shell.execute_reply": "2026-01-18T15:33:43.892267Z",
     "shell.execute_reply.started": "2026-01-18T15:33:43.868475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# COMED_hourly.csv has 66497 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df2 = pd.read_csv(os.path.join(path,'COMED_hourly.csv'), delimiter=',', nrows = nRowsRead)\n",
    "df2.dataframeName = 'COMED_hourly.csv'\n",
    "nRow, nCol = df2.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:46.157174Z",
     "iopub.status.busy": "2026-01-18T15:33:46.156854Z",
     "iopub.status.idle": "2026-01-18T15:33:46.171765Z",
     "shell.execute_reply": "2026-01-18T15:33:46.170478Z",
     "shell.execute_reply.started": "2026-01-18T15:33:46.157123Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>COMED_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>9970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>9428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>9059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>8817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>8743.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  COMED_MW\n",
       "0  2011-12-31 01:00:00    9970.0\n",
       "1  2011-12-31 02:00:00    9428.0\n",
       "2  2011-12-31 03:00:00    9059.0\n",
       "3  2011-12-31 04:00:00    8817.0\n",
       "4  2011-12-31 05:00:00    8743.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:48.811182Z",
     "iopub.status.busy": "2026-01-18T15:33:48.810850Z",
     "iopub.status.idle": "2026-01-18T15:33:48.829250Z",
     "shell.execute_reply": "2026-01-18T15:33:48.828214Z",
     "shell.execute_reply.started": "2026-01-18T15:33:48.811130Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerColumnDistribution(df2, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 3: DAYTON_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:52.655642Z",
     "iopub.status.busy": "2026-01-18T15:33:52.655299Z",
     "iopub.status.idle": "2026-01-18T15:33:52.683691Z",
     "shell.execute_reply": "2026-01-18T15:33:52.682397Z",
     "shell.execute_reply.started": "2026-01-18T15:33:52.655588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# DAYTON_hourly.csv has 121275 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df3 = pd.read_csv(os.path.join(path,'DAYTON_hourly.csv'), delimiter=',', nrows = nRowsRead)\n",
    "df3.dataframeName = 'DAYTON_hourly.csv'\n",
    "nRow, nCol = df3.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:33:58.807725Z",
     "iopub.status.busy": "2026-01-18T15:33:58.807434Z",
     "iopub.status.idle": "2026-01-18T15:33:58.822935Z",
     "shell.execute_reply": "2026-01-18T15:33:58.821372Z",
     "shell.execute_reply.started": "2026-01-18T15:33:58.807682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>DAYTON_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-12-31 01:00:00</td>\n",
       "      <td>1596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-12-31 02:00:00</td>\n",
       "      <td>1517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-12-31 03:00:00</td>\n",
       "      <td>1486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-12-31 04:00:00</td>\n",
       "      <td>1469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-12-31 05:00:00</td>\n",
       "      <td>1472.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  DAYTON_MW\n",
       "0  2004-12-31 01:00:00     1596.0\n",
       "1  2004-12-31 02:00:00     1517.0\n",
       "2  2004-12-31 03:00:00     1486.0\n",
       "3  2004-12-31 04:00:00     1469.0\n",
       "4  2004-12-31 05:00:00     1472.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-18T15:34:01.916482Z",
     "iopub.status.busy": "2026-01-18T15:34:01.916121Z",
     "iopub.status.idle": "2026-01-18T15:34:01.933226Z",
     "shell.execute_reply": "2026-01-18T15:34:01.932433Z",
     "shell.execute_reply.started": "2026-01-18T15:34:01.916421Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerColumnDistribution(df3, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "In this section we define the MLP which we will train on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start by importing the necessary libraries\n",
    "import torch  # Main framework for defining and training the transformer\n",
    "import torch.nn as nn  # Neural network module\n",
    "import torch.optim as optim  # Optimization functions\n",
    "import itertools  # (Optional) For generating structured datasets\n",
    "import math  # For mathematical operations\n",
    "\n",
    "import time # For timing the training process\n",
    "\n",
    "import json # For saving and loading the model\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence # For padding sequences to the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also define a simple MLP model for comparison\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=window_length, hidden_dim=128, output_dim=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)  # No activation on output (for regression)\n",
    "        return x\n",
    "\n",
    "# define model\n",
    "#model = ModuloTransformer(num_primes=len(primes), d_model=256, num_heads=4, num_layers=2, hidden_dim=256)\n",
    "model = MLP(input_dim=window_length, hidden_dim=hidden_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries to package data into batches and in the appropriate format to feed into the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader  # To handle training data efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset AEP_hourly.csv containing the American Electric Power hourly energy consumption\n",
    "\n",
    "Note: we use this dataset as example, but the process can be repeated with the other sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121249, 24) (121249, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load AEP data\n",
    "# Import csv as pandas DataFrame\n",
    "df = pd.read_csv(f\"{path}/AEP_hourly.csv\")\n",
    "# convert \"Datetime\" strings to datetime type\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n",
    "# NOTE data is not ordered properly, see eg\n",
    "# print((df[\"Datetime\"][20:24+1]))\n",
    "# hence order\n",
    "df = df.sort_values(\"Datetime\")\n",
    "\n",
    "# take all MW energy load entries as a numpy array of float32\n",
    "# NB float32 works better with PyTorch\n",
    "series = df[\"AEP_MW\"].values.astype(np.float32)\n",
    "\n",
    "# Sliding window\n",
    "# create input vectors X containing L consecutive values for the energy loads\n",
    "# create target values y containing the next value after each input vector\n",
    "L = window_length  # window length; change as desired\n",
    "X = np.array([series[i:i+L] for i in range(len(series) - L)], dtype=np.float32)\n",
    "y = np.array([series[i+L] for i in range(len(series) - L)], dtype=np.float32)\n",
    "# convert y to (num_samples, 1) shape ie into a 2D array, needed to agree with MLP shape\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# check\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into:\n",
    "\n",
    "(1) training set, used to train the model\n",
    "\n",
    "(2) validation set, used during the training to test the model (e.g. to avoid overfitting)\n",
    "\n",
    "(3) testing set, used to test the model after the training\n",
    "\n",
    "Then package into the appropriate PyTorch formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: (n, L), y: (n, 1)\n",
    "n = len(X)\n",
    "# define (integer) boundaries for train/val/test splits\n",
    "train_end = int(n * 0.7)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "# implement splits\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "# normalise data (z-score normalisation)\n",
    "# NB standardize using train stats only\n",
    "mean = X_train.mean(axis=0, keepdims=True)\n",
    "std = X_train.std(axis=0, keepdims=True) + 1e-8\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Torch datasets/loaders\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_ds = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "test_ds = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first batch of data as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inputs (time series): torch.Size([128, 24])\n",
      "Batch Inputs (time series): tensor([[ 0.8220,  0.8053,  0.6420,  ...,  0.5757,  0.6114,  0.6040],\n",
      "        [-0.4044, -0.3664, -0.3629,  ..., -0.5350, -0.5063, -0.4004],\n",
      "        [-0.1743, -0.2050, -0.3299,  ..., -0.0714, -0.0473, -0.0842],\n",
      "        ...,\n",
      "        [ 1.2248,  1.1417,  1.1631,  ...,  2.5982,  2.2393,  1.9619],\n",
      "        [-0.5449, -0.2217,  0.4286,  ..., -0.3907, -0.4330, -0.4248],\n",
      "        [ 1.7326,  1.4746,  1.2876,  ...,  2.0236,  1.8952,  1.7307]])\n",
      "Batch Targets (next step): torch.Size([128, 1])\n",
      "Batch Targets (next step): tensor([[17445.],\n",
      "        [14792.],\n",
      "        [15410.],\n",
      "        [12986.],\n",
      "        [12384.],\n",
      "        [11837.],\n",
      "        [16354.],\n",
      "        [18631.],\n",
      "        [14776.],\n",
      "        [14511.],\n",
      "        [16965.],\n",
      "        [20836.],\n",
      "        [17843.],\n",
      "        [12416.],\n",
      "        [20702.],\n",
      "        [19695.],\n",
      "        [16609.],\n",
      "        [11578.],\n",
      "        [18566.],\n",
      "        [21644.],\n",
      "        [19016.],\n",
      "        [14756.],\n",
      "        [14221.],\n",
      "        [15096.],\n",
      "        [18626.],\n",
      "        [18114.],\n",
      "        [14842.],\n",
      "        [19142.],\n",
      "        [17651.],\n",
      "        [14635.],\n",
      "        [15375.],\n",
      "        [19363.],\n",
      "        [14672.],\n",
      "        [13231.],\n",
      "        [24639.],\n",
      "        [16380.],\n",
      "        [16732.],\n",
      "        [17186.],\n",
      "        [15762.],\n",
      "        [14593.],\n",
      "        [11665.],\n",
      "        [14437.],\n",
      "        [14785.],\n",
      "        [13332.],\n",
      "        [17808.],\n",
      "        [17532.],\n",
      "        [17864.],\n",
      "        [15063.],\n",
      "        [13002.],\n",
      "        [20389.],\n",
      "        [17668.],\n",
      "        [11943.],\n",
      "        [11386.],\n",
      "        [11337.],\n",
      "        [13899.],\n",
      "        [16517.],\n",
      "        [14287.],\n",
      "        [15920.],\n",
      "        [11013.],\n",
      "        [15324.],\n",
      "        [12664.],\n",
      "        [12782.],\n",
      "        [20806.],\n",
      "        [16504.],\n",
      "        [13331.],\n",
      "        [16501.],\n",
      "        [16551.],\n",
      "        [17779.],\n",
      "        [16138.],\n",
      "        [19839.],\n",
      "        [15959.],\n",
      "        [16890.],\n",
      "        [14333.],\n",
      "        [20782.],\n",
      "        [10993.],\n",
      "        [12237.],\n",
      "        [11286.],\n",
      "        [16641.],\n",
      "        [11770.],\n",
      "        [18706.],\n",
      "        [11493.],\n",
      "        [14523.],\n",
      "        [16609.],\n",
      "        [16341.],\n",
      "        [15538.],\n",
      "        [13616.],\n",
      "        [16313.],\n",
      "        [13220.],\n",
      "        [17067.],\n",
      "        [16288.],\n",
      "        [12762.],\n",
      "        [13502.],\n",
      "        [12239.],\n",
      "        [10303.],\n",
      "        [14458.],\n",
      "        [12900.],\n",
      "        [12308.],\n",
      "        [15073.],\n",
      "        [14979.],\n",
      "        [15640.],\n",
      "        [14858.],\n",
      "        [14162.],\n",
      "        [12553.],\n",
      "        [17474.],\n",
      "        [13332.],\n",
      "        [17430.],\n",
      "        [17301.],\n",
      "        [18411.],\n",
      "        [18412.],\n",
      "        [15335.],\n",
      "        [13532.],\n",
      "        [15142.],\n",
      "        [15862.],\n",
      "        [14392.],\n",
      "        [11988.],\n",
      "        [16945.],\n",
      "        [14159.],\n",
      "        [22137.],\n",
      "        [14517.],\n",
      "        [14984.],\n",
      "        [14219.],\n",
      "        [14636.],\n",
      "        [16712.],\n",
      "        [10593.],\n",
      "        [18102.],\n",
      "        [20305.],\n",
      "        [14880.],\n",
      "        [19255.]])\n"
     ]
    }
   ],
   "source": [
    "# Check one batch of data\n",
    "for batch in train_loader:\n",
    "    inputs, targets = batch  # Unpack batch\n",
    "    print(f\"Batch Inputs (time series): {inputs.shape}\")  # Should be (batch_size, window_length)\n",
    "    print(f\"Batch Inputs (time series): {inputs}\")\n",
    "    print(f\"Batch Targets (next step): {targets.shape}\")  # Should be (batch_size,1)\n",
    "    print(f\"Batch Targets (next step): {targets}\")\n",
    "    break  # Only print the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training loop and train the model.\n",
    "\n",
    "Note:\n",
    "\n",
    "(1) we use Mean Squared Loss as a loss function, since the output is a float representing the energy power in MW\n",
    "\n",
    "(2) we leave the option to turn on a scheduler to update the learining rate during training\n",
    "\n",
    "(3) we keep track of both training and validation loss, e.g. to make sure the model is training but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | train 67748665.4503 | val 11158326.4065\n",
      "Epoch 2/100 | train 3145038.1846 | val 334892.3539\n",
      "Epoch 3/100 | train 213141.9958 | val 133895.8595\n",
      "Epoch 4/100 | train 124679.5839 | val 87948.8426\n",
      "Epoch 5/100 | train 91365.3329 | val 65579.0720\n",
      "Epoch 6/100 | train 74344.0074 | val 54354.1324\n",
      "Epoch 7/100 | train 65169.6513 | val 55746.7867\n",
      "Epoch 8/100 | train 59672.0561 | val 47910.1717\n",
      "Epoch 9/100 | train 57352.2499 | val 49908.6823\n",
      "Epoch 10/100 | train 55898.1353 | val 50043.5760\n",
      "Epoch 11/100 | train 55378.5034 | val 47716.3762\n",
      "Epoch 12/100 | train 54828.8872 | val 47455.1587\n",
      "Epoch 13/100 | train 55034.7395 | val 46367.5195\n",
      "Epoch 14/100 | train 54571.9318 | val 42901.0380\n",
      "Epoch 15/100 | train 53597.1951 | val 41033.4582\n",
      "Epoch 16/100 | train 53419.4706 | val 43922.5276\n",
      "Epoch 17/100 | train 54568.8677 | val 42343.4849\n",
      "Epoch 18/100 | train 52872.3416 | val 43433.1063\n",
      "Epoch 19/100 | train 52825.9701 | val 43088.0919\n",
      "Epoch 20/100 | train 52670.6346 | val 40839.4802\n",
      "Epoch 21/100 | train 52974.6132 | val 42198.3665\n",
      "Epoch 22/100 | train 52559.0360 | val 41026.3841\n",
      "Epoch 23/100 | train 52154.8045 | val 39847.2190\n",
      "Epoch 24/100 | train 52106.8244 | val 40591.6510\n",
      "Epoch 25/100 | train 51917.9195 | val 41197.4042\n",
      "Epoch 26/100 | train 51745.7207 | val 41408.0017\n",
      "Epoch 27/100 | train 51590.2265 | val 42658.1722\n",
      "Epoch 28/100 | train 51272.2615 | val 40635.1167\n",
      "Epoch 29/100 | train 52067.4086 | val 41453.9837\n",
      "Epoch 30/100 | train 50768.8843 | val 41138.3498\n",
      "Epoch 31/100 | train 51046.0078 | val 46599.3695\n",
      "Epoch 32/100 | train 51080.6728 | val 48285.2318\n",
      "Epoch 33/100 | train 50699.2444 | val 41582.5353\n",
      "Epoch 34/100 | train 50734.7442 | val 45775.7516\n",
      "Epoch 35/100 | train 50278.0642 | val 43742.4082\n",
      "Epoch 36/100 | train 50646.9075 | val 47643.8061\n",
      "Epoch 37/100 | train 50098.5732 | val 41955.1764\n",
      "Epoch 38/100 | train 50078.6161 | val 43732.5779\n",
      "Epoch 39/100 | train 50451.6056 | val 50536.4427\n",
      "Epoch 40/100 | train 50363.8060 | val 42938.3307\n",
      "Epoch 41/100 | train 49699.9692 | val 43123.0025\n",
      "Epoch 42/100 | train 49870.9286 | val 62029.3751\n",
      "Epoch 43/100 | train 50085.0756 | val 48608.8720\n",
      "Epoch 44/100 | train 49783.7272 | val 41530.7130\n",
      "Epoch 45/100 | train 49782.9182 | val 46070.4084\n",
      "Epoch 46/100 | train 49083.4175 | val 41428.3627\n",
      "Epoch 47/100 | train 49181.0462 | val 41444.4132\n",
      "Epoch 48/100 | train 49277.6257 | val 46090.4451\n",
      "Epoch 49/100 | train 49353.5494 | val 42818.0151\n",
      "Epoch 50/100 | train 49433.3907 | val 44390.7549\n",
      "Epoch 51/100 | train 49028.2069 | val 42735.9896\n",
      "Epoch 52/100 | train 49042.7361 | val 40644.9657\n",
      "Epoch 53/100 | train 49279.8380 | val 52651.3811\n",
      "Epoch 54/100 | train 48663.7044 | val 41015.2718\n",
      "Epoch 55/100 | train 49024.4332 | val 41734.4212\n",
      "Epoch 56/100 | train 49031.1777 | val 47986.6372\n",
      "Epoch 57/100 | train 48537.1216 | val 38252.9468\n",
      "Epoch 58/100 | train 47944.6514 | val 38773.8558\n",
      "Epoch 59/100 | train 48776.9455 | val 44684.1725\n",
      "Epoch 60/100 | train 48583.7120 | val 42485.3152\n",
      "Epoch 61/100 | train 48707.0341 | val 44207.9916\n",
      "Epoch 62/100 | train 47871.1333 | val 46026.9099\n",
      "Epoch 63/100 | train 48383.5762 | val 41235.2418\n",
      "Epoch 64/100 | train 48406.6482 | val 38954.9822\n",
      "Epoch 65/100 | train 48139.7967 | val 37618.6360\n",
      "Epoch 66/100 | train 48100.7426 | val 38581.4422\n",
      "Epoch 67/100 | train 47965.2880 | val 41978.7658\n",
      "Epoch 68/100 | train 48015.9955 | val 38328.6669\n",
      "Epoch 69/100 | train 47397.7687 | val 39611.4118\n",
      "Epoch 70/100 | train 47430.4375 | val 45893.7666\n",
      "Epoch 71/100 | train 47543.5176 | val 41149.5753\n",
      "Epoch 72/100 | train 47113.9850 | val 41004.3518\n",
      "Epoch 73/100 | train 47031.4576 | val 36605.4906\n",
      "Epoch 74/100 | train 46746.0387 | val 40370.9844\n",
      "Epoch 75/100 | train 45757.5373 | val 36382.0823\n",
      "Epoch 76/100 | train 44925.4201 | val 35840.7013\n",
      "Epoch 77/100 | train 44065.8612 | val 35216.6303\n",
      "Epoch 78/100 | train 44194.3029 | val 40789.4226\n",
      "Epoch 79/100 | train 43164.8515 | val 45338.8866\n",
      "Epoch 80/100 | train 43395.7935 | val 35702.4944\n",
      "Epoch 81/100 | train 42817.9274 | val 34331.1836\n",
      "Epoch 82/100 | train 42515.3859 | val 35092.2917\n",
      "Epoch 83/100 | train 42023.1175 | val 36147.1592\n",
      "Epoch 84/100 | train 41660.8550 | val 45191.2130\n",
      "Epoch 85/100 | train 41463.2110 | val 39288.2148\n",
      "Epoch 86/100 | train 41126.3618 | val 35814.7681\n",
      "Epoch 87/100 | train 41197.4077 | val 34807.9841\n",
      "Epoch 88/100 | train 41194.9005 | val 33577.9710\n",
      "Epoch 89/100 | train 40536.9658 | val 32616.6087\n",
      "Epoch 90/100 | train 39837.2976 | val 34349.7194\n",
      "Epoch 91/100 | train 40345.9026 | val 32443.4663\n",
      "Epoch 92/100 | train 39543.9988 | val 35987.6042\n",
      "Epoch 93/100 | train 39688.6783 | val 34378.3577\n",
      "Epoch 94/100 | train 41310.2495 | val 63617.5828\n",
      "Epoch 95/100 | train 39859.4178 | val 33117.2603\n",
      "Epoch 96/100 | train 38768.7717 | val 35784.3826\n",
      "Epoch 97/100 | train 38597.9271 | val 33984.0726\n",
      "Epoch 98/100 | train 38054.9683 | val 38268.0903\n",
      "Epoch 99/100 | train 38024.6589 | val 31323.8290\n",
      "Epoch 100/100 | train 37635.7653 | val 31089.9903\n",
      "Training completed in 74.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now we define the training loop\n",
    "# We define the loss function (Mean Squared Error) and the optimizer (Adam)\n",
    "# Then we iterate over the data in batches, perform forward pass, compute loss, backpropagate and update weights\n",
    "\n",
    "# Define Mean Squared Error loss (for regression)\n",
    "#loss_fn = nn.MSELoss()\n",
    "# Define Cross Entropy loss (for classification)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)  # Reduce LR by gamma after step_size epochs\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)  # Cosine annealing scheduler, gradually reduces learning rate, specify eta_min=X for minimum LR value (default 0)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)  # Reduce LR on plateau, reduce LR by factor of 0.5 if validation loss does not improve for 10 epochs\n",
    "\n",
    "# Check output for a single training step\n",
    "#optimizer.zero_grad()  # Reset gradients\n",
    "#test_outputs = model(test_inputs)  # Forward pass (predict N)\n",
    "#test_loss = loss_fn(test_outputs, test_targets)  # Compute loss\n",
    "#test_loss.backward()  # Backpropagation\n",
    "#optimizer.step()  # Update weights\n",
    "#print(\"Model Output After One Training Step:\")\n",
    "#print(model(test_inputs))\n",
    "\n",
    "\n",
    "start_time = time.time()  # Track how long training takes\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0  # Track total loss for the epoch\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for inputs, targets in train_loader:  # Iterate over batches\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(inputs)  # Forward pass (predict N)\n",
    "        loss = loss_fn(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        train_loss += loss.item()  # Keep track of loss\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler every epoch\n",
    "    #scheduler.step()\n",
    "    # Use for the ReduceLROnPlateau scheduler\n",
    "    #scheduler.step(total_loss)\n",
    "\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")  # Print total time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the trained model\n",
    "\n",
    "We begin by computing mean squared error (MSE), root mean squared error (RMSE) and mean absolute error (MAE) with respect to the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 28558.9980 | RMSE: 168.9941 | MAE: 125.0897\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "preds = []\n",
    "targets_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        preds.append(outputs.cpu())\n",
    "        targets_all.append(targets.cpu())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "targets_all = torch.cat(targets_all).numpy()\n",
    "\n",
    "# Metrics\n",
    "mse = ((preds - targets_all) ** 2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.abs(preds - targets_all).mean()\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compare MSE/RMSE/MAE against a simple baseline, obtained by using the MW value for the last hour (in each sequence in X_test) as prediction for the next hour. If the model has trained well we expect it to give better results than this baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 286020.5312 | RMSE: 534.8089 | MAE: 417.4123\n"
     ]
    }
   ],
   "source": [
    "# De-normalize last input value to MW\n",
    "last_norm = X_test[:, -1]  # z-score-normalized last value\n",
    "last_raw = last_norm * std[0, -1] + mean[0, -1] # de-normalize\n",
    "\n",
    "baseline_pred = last_raw\n",
    "baseline_true = y_test.squeeze()\n",
    "\n",
    "baseline_mse = ((baseline_pred - baseline_true) ** 2).mean()\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "baseline_mae = np.abs(baseline_pred - baseline_true).mean()\n",
    "\n",
    "print(f\"Baseline MSE: {baseline_mse:.4f} | RMSE: {baseline_rmse:.4f} | MAE: {baseline_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we create a table displaying predicted VS actual power for a few datapoints in the training set, including absolute and relative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>error</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>rel_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12168.0</td>\n",
       "      <td>12234.470703</td>\n",
       "      <td>66.470703</td>\n",
       "      <td>66.470703</td>\n",
       "      <td>0.005463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12568.0</td>\n",
       "      <td>12540.705078</td>\n",
       "      <td>-27.294922</td>\n",
       "      <td>27.294922</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13203.0</td>\n",
       "      <td>13282.333984</td>\n",
       "      <td>79.333984</td>\n",
       "      <td>79.333984</td>\n",
       "      <td>0.006009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14019.0</td>\n",
       "      <td>13838.955078</td>\n",
       "      <td>-180.044922</td>\n",
       "      <td>180.044922</td>\n",
       "      <td>0.012843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14901.0</td>\n",
       "      <td>14760.707031</td>\n",
       "      <td>-140.292969</td>\n",
       "      <td>140.292969</td>\n",
       "      <td>0.009415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15815.0</td>\n",
       "      <td>15737.275391</td>\n",
       "      <td>-77.724609</td>\n",
       "      <td>77.724609</td>\n",
       "      <td>0.004915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16821.0</td>\n",
       "      <td>16770.187500</td>\n",
       "      <td>-50.812500</td>\n",
       "      <td>50.812500</td>\n",
       "      <td>0.003021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17623.0</td>\n",
       "      <td>17741.884766</td>\n",
       "      <td>118.884766</td>\n",
       "      <td>118.884766</td>\n",
       "      <td>0.006746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18382.0</td>\n",
       "      <td>18430.199219</td>\n",
       "      <td>48.199219</td>\n",
       "      <td>48.199219</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18931.0</td>\n",
       "      <td>19138.367188</td>\n",
       "      <td>207.367188</td>\n",
       "      <td>207.367188</td>\n",
       "      <td>0.010954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19409.0</td>\n",
       "      <td>19460.099609</td>\n",
       "      <td>51.099609</td>\n",
       "      <td>51.099609</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19312.0</td>\n",
       "      <td>19735.808594</td>\n",
       "      <td>423.808594</td>\n",
       "      <td>423.808594</td>\n",
       "      <td>0.021945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19231.0</td>\n",
       "      <td>19282.074219</td>\n",
       "      <td>51.074219</td>\n",
       "      <td>51.074219</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19295.0</td>\n",
       "      <td>19066.019531</td>\n",
       "      <td>-228.980469</td>\n",
       "      <td>228.980469</td>\n",
       "      <td>0.011867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19451.0</td>\n",
       "      <td>19028.416016</td>\n",
       "      <td>-422.583984</td>\n",
       "      <td>422.583984</td>\n",
       "      <td>0.021726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18967.0</td>\n",
       "      <td>18927.917969</td>\n",
       "      <td>-39.082031</td>\n",
       "      <td>39.082031</td>\n",
       "      <td>0.002061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18434.0</td>\n",
       "      <td>18342.230469</td>\n",
       "      <td>-91.769531</td>\n",
       "      <td>91.769531</td>\n",
       "      <td>0.004978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18097.0</td>\n",
       "      <td>17991.380859</td>\n",
       "      <td>-105.619141</td>\n",
       "      <td>105.619141</td>\n",
       "      <td>0.005836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16983.0</td>\n",
       "      <td>17144.476562</td>\n",
       "      <td>161.476562</td>\n",
       "      <td>161.476562</td>\n",
       "      <td>0.009508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15641.0</td>\n",
       "      <td>15435.796875</td>\n",
       "      <td>-205.203125</td>\n",
       "      <td>205.203125</td>\n",
       "      <td>0.013120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target          pred       error   abs_error  rel_error\n",
       "0   12168.0  12234.470703   66.470703   66.470703   0.005463\n",
       "1   12568.0  12540.705078  -27.294922   27.294922   0.002172\n",
       "2   13203.0  13282.333984   79.333984   79.333984   0.006009\n",
       "3   14019.0  13838.955078 -180.044922  180.044922   0.012843\n",
       "4   14901.0  14760.707031 -140.292969  140.292969   0.009415\n",
       "5   15815.0  15737.275391  -77.724609   77.724609   0.004915\n",
       "6   16821.0  16770.187500  -50.812500   50.812500   0.003021\n",
       "7   17623.0  17741.884766  118.884766  118.884766   0.006746\n",
       "8   18382.0  18430.199219   48.199219   48.199219   0.002622\n",
       "9   18931.0  19138.367188  207.367188  207.367188   0.010954\n",
       "10  19409.0  19460.099609   51.099609   51.099609   0.002633\n",
       "11  19312.0  19735.808594  423.808594  423.808594   0.021945\n",
       "12  19231.0  19282.074219   51.074219   51.074219   0.002656\n",
       "13  19295.0  19066.019531 -228.980469  228.980469   0.011867\n",
       "14  19451.0  19028.416016 -422.583984  422.583984   0.021726\n",
       "15  18967.0  18927.917969  -39.082031   39.082031   0.002061\n",
       "16  18434.0  18342.230469  -91.769531   91.769531   0.004978\n",
       "17  18097.0  17991.380859 -105.619141  105.619141   0.005836\n",
       "18  16983.0  17144.476562  161.476562  161.476562   0.009508\n",
       "19  15641.0  15435.796875 -205.203125  205.203125   0.013120"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "targets_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        preds.append(outputs.cpu().numpy())\n",
    "        targets_all.append(targets.cpu().numpy())\n",
    "\n",
    "preds = np.vstack(preds).squeeze()\n",
    "targets_all = np.vstack(targets_all).squeeze()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"target\": targets_all,\n",
    "    \"pred\": preds\n",
    "})\n",
    "#results[\"error\"] = results[\"pred\"] - results[\"target\"]\n",
    "results[\"abs_error\"] = (results[\"pred\"] - results[\"target\"]).abs()\n",
    "results[\"rel_error\"] = results[\"abs_error\"]/results[\"target\"]\n",
    "\n",
    "results.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 48149,
     "sourceId": 87794,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 25114,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
